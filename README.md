
# **LAB 2 **

## **Description**
Ce projet a pour objectif d’approfondir les connaissances sur la bibliothèque **PyTorch** en développant des architectures neuronales avancées pour la vision par ordinateur. Il est structuré en deux parties principales :  

1. **Réseaux de Neurones Convolutifs (CNN)** :  
   - Conception et évaluation d'un CNN pour classifier les images du dataset MNIST.  
   - Exploration des modèles **Faster R-CNN** pour une classification et une détection plus précises.  
   - Fine-tuning de modèles pré-entraînés comme **VGG16** et **AlexNet** sur le dataset MNIST.  
   - Comparaison des performances selon plusieurs métriques : précision, F1-score, perte et temps d'entraînement.  

2. **Vision Transformers (ViT)** :  
   - Implémentation d'une architecture **ViT** à partir de zéro . 
   - Classification d’images avec le ViT sur le même dataset.  
   - Comparaison des résultats obtenus avec ceux des architectures CNN et Faster R-CNN.  

## **Objectifs d’apprentissage**
- Maîtriser la conception et l’implémentation de modèles basés sur **PyTorch**.  
- Explorer des architectures avancées telles que **Faster R-CNN** et **Vision Transformers**.  
- Analyser et comparer les performances des modèles sur des tâches de vision par ordinateur.  
- Comprendre l'impact du fine-tuning des modèles pré-entraînés sur les résultats.  



## **Synthèse**
À l’issue de ce projet, les principales conclusions incluent :  
- La comparaison des performances entre les architectures CNN, Faster R-CNN et Vision Transformers sur des données simples comme MNIST.  
- Les avantages du fine-tuning des modèles pré-entraînés pour améliorer les résultats.  
- Une meilleure compréhension des forces et limites de chaque architecture pour les tâches de vision par ordinateur.  

## **Ressources**
- [MNIST Dataset](https://www.kaggle.com/datasets/hojjatk/mnist-dataset)  
- [Tutoriel Vision Transformers](https://medium.com/mlearning-ai/vision-transformers-from-scratch-pytorch-a-step-by-step-guide-96c3313c2e0c)  

---

