
# LAB 2 

## **Description**
Ce projet a pour objectif d’approfondir les connaissances sur la bibliothèque **PyTorch** en développant des architectures neuronales avancées pour la vision par ordinateur. Il est structuré en deux parties principales :  

1. **Réseaux de Neurones Convolutifs (CNN)** :  
   - Conception et évaluation d'un CNN pour classifier les images du dataset MNIST.  
   - Exploration des modèles **Faster R-CNN** pour une classification et une détection plus précises.  
   - Fine-tuning de modèles pré-entraînés comme **VGG16** et **AlexNet** sur le dataset MNIST.  
   - Comparaison des performances selon plusieurs métriques : précision, F1-score, perte et temps d'entraînement.  

2. **Vision Transformers (ViT)** :  
   - Implémentation d'une architecture **ViT** à partir de zéro . 
   - Classification d’images avec le ViT sur le même dataset.  
   - Comparaison des résultats obtenus avec ceux des architectures CNN et Faster R-CNN.  

## **Objectifs d’apprentissage**
- Maîtriser la conception et l’implémentation de modèles basés sur **PyTorch**.  
- Explorer des architectures avancées telles que **Faster R-CNN** et **Vision Transformers**.  
- Analyser et comparer les performances des modèles sur des tâches de vision par ordinateur.  
- Comprendre l'impact du fine-tuning des modèles pré-entraînés sur les résultats.  



## **Synthèse**
Ce projet vise à approfondir les connaissances sur la bibliothèque PyTorch en développant des architectures neuronales avancées pour la vision par ordinateur. La première partie est consacrée à la conception et à l'évaluation de réseaux de neurones convolutifs (CNN) pour la classification d'images à l'aide du dataset MNIST. Elle inclut également une exploration des modèles Faster R-CNN et des techniques de fine-tuning basées sur des modèles pré-entraînés comme VGG16 et AlexNet. Les performances des différentes approches sont comparées selon plusieurs métriques, notamment la précision, le score F1, la perte et le temps d'entraînement. La deuxième partie se concentre sur les Vision Transformers (ViT), une architecture innovante ayant démontré des performances remarquables en vision par ordinateur. En suivant un tutoriel de référence, un modèle ViT est implémenté à partir de zéro et utilisé pour une tâche de classification sur le même dataset, puis comparé aux résultats obtenus avec les modèles CNN et Faster R-CNN. Ce projet permet de maîtriser la conception et l'évaluation de modèles d'apprentissage profond, de comprendre les particularités des architectures CNN et ViT, et de tirer des conclusions sur leurs performances respectives dans différents contextes.

## **Ressources**
- [MNIST Dataset](https://www.kaggle.com/datasets/hojjatk/mnist-dataset)  
- [Tutoriel Vision Transformers](https://medium.com/mlearning-ai/vision-transformers-from-scratch-pytorch-a-step-by-step-guide-96c3313c2e0c)  

---

